{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# These models are voting models based off the above models\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Data prep\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Model evaluations\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import KFold,StratifiedKFold, ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models NEW HPS\n",
    "\n",
    "ADBC = AdaBoostClassifier(base_estimator=None, learning_rate=0.1, n_estimators=200)\n",
    "XGB = XGBClassifier(n_estimators=100, learning_rate=0.1, colsample_bytree=0.4, max_depth=15, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8)\n",
    "svc = SVC(C=1, decision_function_shape='ovo', kernel='linear', probability=True, shrinking=True)\n",
    "KNC = KNeighborsClassifier()\n",
    "RFC = RandomForestClassifier(criterion='gini', max_depth=9, max_leaf_nodes=10, min_samples_split=9, n_estimators=200, oob_score=True, warm_start=True)\n",
    "\n",
    "GBC = GradientBoostingClassifier(criterion='friedman_mse', learning_rate=0.01, loss='deviance', n_estimators=200, subsample=1)\n",
    "HGBC = HistGradientBoostingClassifier(learning_rate=0.01, loss='auto', max_iter=100, max_leaf_nodes=20, min_samples_leaf=15)\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "\n",
    "# Imputer\n",
    "imputer = SimpleImputer()\n",
    "MMScaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADBC = AdaBoostClassifier()\n",
    "XGB = XGBClassifier()\n",
    "svc = SVC()\n",
    "KNC = KNeighborsClassifier()\n",
    "RFC = RandomForestClassifier()\n",
    "GBC = GradientBoostingClassifier()\n",
    "HGBC = HistGradientBoostingClassifier()\n",
    "QDA = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Start (ET)</th>\n",
       "      <th>Visitor</th>\n",
       "      <th>Vis PTS</th>\n",
       "      <th>Home</th>\n",
       "      <th>Home PTS</th>\n",
       "      <th>Home Win</th>\n",
       "      <th>2019 HW</th>\n",
       "      <th>2019 HGF</th>\n",
       "      <th>2019 HGA</th>\n",
       "      <th>...</th>\n",
       "      <th>2020 HGA</th>\n",
       "      <th>2020 HMP</th>\n",
       "      <th>2019 VW</th>\n",
       "      <th>2019 VGF</th>\n",
       "      <th>2019 VGA</th>\n",
       "      <th>2019 VMP</th>\n",
       "      <th>2020 VW</th>\n",
       "      <th>2020 VGF</th>\n",
       "      <th>2020 VGA</th>\n",
       "      <th>2020 VMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>8:00p</td>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Toronto Raptors</td>\n",
       "      <td>130.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>10:30p</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Los Angeles Clippers</td>\n",
       "      <td>112.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>7:00p</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>126.0</td>\n",
       "      <td>True</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>7:00p</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>119.0</td>\n",
       "      <td>Indiana Pacers</td>\n",
       "      <td>110.0</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>7:00p</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>94.0</td>\n",
       "      <td>True</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>8:00p</td>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>8:00p</td>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>8:00p</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>28.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>8:30p</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>9:30p</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>12.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1979 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Start (ET)                 Visitor  Vis PTS  \\\n",
       "0    2019-10-22      8:00p    New Orleans Pelicans    122.0   \n",
       "1    2019-10-22     10:30p      Los Angeles Lakers    102.0   \n",
       "2    2019-10-23      7:00p           Chicago Bulls    125.0   \n",
       "3    2019-10-23      7:00p         Detroit Pistons    119.0   \n",
       "4    2019-10-23      7:00p     Cleveland Cavaliers     85.0   \n",
       "...         ...        ...                     ...      ...   \n",
       "1974 2021-04-16      8:00p       Memphis Grizzlies      NaN   \n",
       "1975 2021-04-16      8:00p          Denver Nuggets      NaN   \n",
       "1976 2021-04-16      8:00p              Miami Heat      NaN   \n",
       "1977 2021-04-16      8:30p  Portland Trail Blazers      NaN   \n",
       "1978 2021-04-16      9:30p         New York Knicks      NaN   \n",
       "\n",
       "                        Home  Home PTS  Home Win  2019 HW  2019 HGF  2019 HGA  \\\n",
       "0            Toronto Raptors     130.0      True      2.0      13.0      30.0   \n",
       "1       Los Angeles Clippers     112.0      True      4.0       4.0      17.5   \n",
       "2          Charlotte Hornets     126.0      True     23.0      30.0      19.0   \n",
       "3             Indiana Pacers     110.0     False      7.0      23.0      28.0   \n",
       "4              Orlando Magic      94.0      True     18.0      24.0      26.0   \n",
       "...                      ...       ...       ...      ...       ...       ...   \n",
       "1974           Chicago Bulls       NaN     False     24.0      27.0      17.5   \n",
       "1975         Houston Rockets       NaN     False      9.5       2.0       8.5   \n",
       "1976  Minnesota Timberwolves       NaN     False     28.5      12.0       3.0   \n",
       "1977       San Antonio Spurs       NaN     False     19.0       8.0       6.0   \n",
       "1978        Dallas Mavericks       NaN     False     12.5       3.0      14.5   \n",
       "\n",
       "      ...  2020 HGA  2020 HMP  2019 VW  2019 VGF  2019 VGA  2019 VMP  2020 VW  \\\n",
       "0     ...      17.5      14.0     21.0       5.0       4.0      20.0     20.0   \n",
       "1     ...      25.0       3.0      3.0      11.0      27.0       5.0      7.5   \n",
       "2     ...      16.0      19.0     24.0      27.0      17.5      22.0     21.5   \n",
       "3     ...      11.0      15.5     26.5      25.0      16.0      23.0     28.0   \n",
       "4     ...      14.5      29.0     28.5      26.0       8.5      28.0     25.5   \n",
       "...   ...       ...       ...      ...       ...       ...       ...      ...   \n",
       "1974  ...      10.0      20.0     16.5      14.0      10.0      18.5     16.0   \n",
       "1975  ...       7.0      26.0      6.0      18.5      20.0      11.0      6.0   \n",
       "1976  ...       3.0      27.0      9.5      15.0      21.0       8.0     12.5   \n",
       "1977  ...      13.0      21.0     14.5       6.0       5.0      17.0      9.0   \n",
       "1978  ...      23.0      10.5     25.0      29.0      12.5      26.0     14.5   \n",
       "\n",
       "      2020 VGF  2020 VGA  2020 VMP  \n",
       "0          8.0       4.0      17.0  \n",
       "1         23.0      29.0       7.0  \n",
       "2         15.0      10.0      20.0  \n",
       "3         24.0      17.5      23.0  \n",
       "4         30.0      19.0      28.0  \n",
       "...        ...       ...       ...  \n",
       "1974      14.0      14.5      12.0  \n",
       "1975       4.5      22.0       6.0  \n",
       "1976      26.0      28.0      18.0  \n",
       "1977       7.0       5.0      15.5  \n",
       "1978      28.0      30.0      13.0  \n",
       "\n",
       "[1979 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### READING DATA #####\n",
    "\n",
    "use_current_year = True\n",
    "year = 2020\n",
    "prev_year = year - 1\n",
    "next_year = year + 1\n",
    "\n",
    "season_dict = {2020: ['2020-12-1', '2021-06-30'],\n",
    "            2019: ['2019-10-1', '2020-10-30'],\n",
    "             2018: ['2018-10-1', '2019-06-30'],\n",
    "             2017: ['2017-10-1', '2018-06-30'],\n",
    "             2016: ['2016-10-1', '2017-06-30']}\n",
    "\n",
    "\n",
    "data = pd.read_excel('./content/NBA_COMBINED.xlsx', sheet_name='Games', parse_dates=['Date'])\n",
    "\n",
    "if use_current_year:\n",
    "    rankings = pd.read_csv('./Web Scraping/Power_rankings.csv', usecols=['Name',f'{prev_year} WRank', f'{prev_year} GARank', f'{prev_year} GFRank', f'{prev_year} MRank',\n",
    "                                                                     f'{year} WRank', f'{year} GARank', f'{year} GFRank', f'{year} MRank'])\n",
    "else:\n",
    "    rankings = pd.read_csv('./Web Scraping/Power_rankings.csv', usecols=['Name','2016 WRank', '2016 GARank', '2016 GFRank', '2016 MRank'])\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data[['Date', 'Start (ET)', 'Visitor', 'Vis PTS', 'Home', 'Home PTS']]\n",
    "\n",
    "# Drop unnecessary rows\n",
    "data = data[(data['Date'] > season_dict[prev_year][0]) & (data['Date'] < season_dict[year][1])]\n",
    "\n",
    "# Create prediction column\n",
    "data['Home Win'] = data['Home PTS'] > data['Vis PTS']\n",
    "\n",
    "# Create home and vis rankings DF\n",
    "home_rank = rankings.copy()\n",
    "vis_rank = rankings.copy()\n",
    "\n",
    "if use_current_year:\n",
    "    home_rank.columns = ['Home', f'{prev_year} HW', f'{prev_year} HGF', f'{prev_year} HGA', f'{prev_year} HMP', f'{year} HW', f'{year} HGF', f'{year} HGA', f'{year} HMP']\n",
    "    vis_rank.columns = ['Visitor', f'{prev_year} VW', f'{prev_year} VGF', f'{prev_year} VGA', f'{prev_year} VMP', f'{year} VW', f'{year} VGF', f'{year} VGA', f'{year} VMP']\n",
    "else:\n",
    "    home_rank.columns = ['Home', f'{prev_year} HW', f'{prev_year} HGF', f'{prev_year} HGA', f'{prev_year} HMP']\n",
    "    vis_rank.columns = ['Visitor', f'{prev_year} VW', f'{prev_year} VGF', f'{prev_year} VGA', f'{prev_year} VMP']\n",
    "\n",
    "\n",
    "# Merge rankings and df columns\n",
    "data = data.merge(home_rank, on='Home', how='left')\n",
    "data = data.merge(vis_rank, on='Visitor', how='left')\n",
    "\n",
    "# Set current year columns for last year games to nan\n",
    "# index_to_nan = data[(data['Date'] > season_dict[year][0])].index[0]\n",
    "# data.loc[:index_to_nan,f'{year} HW':] = np.NaN\n",
    "\n",
    "# Set X/y_train_and_test\n",
    "rows_with_results = len(data) - len(data[data['Vis PTS'].isna()])\n",
    "\n",
    "# Training and testing\n",
    "X_train_and_test = data.loc[:rows_with_results-1,f'{prev_year} HW':]\n",
    "y_train_and_test = data['Home Win'][:rows_with_results-1]\n",
    "y_train_and_test = y_train_and_test.astype(bool)\n",
    "\n",
    "# Make future predictions dataframe and teams and dates as well\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = data.loc[:,f'{prev_year} HW':]\n",
    "y = data['Home Win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model function\n",
    "\n",
    "def train_model(X_train_and_test, y_train_and_test, model):\n",
    "    ''' Scale, Split, Impute and Train one model '''\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_and_test, y_train_and_test, test_size=test_size, shuffle=False)\n",
    "    pipe = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), model)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    \n",
    "    # Combine predictions with actuals\n",
    "    preds_df = pd.DataFrame(preds, columns=['Predictions'])\n",
    "    preds_df.index = pd.RangeIndex(start=y_train.last_valid_index()+1, stop=y_train.last_valid_index()+1 + len(y_test))\n",
    "    predictions_array.append(preds_df)\n",
    "    preds_and_true = pd.concat([y_test, preds_df], axis=1, ignore_index=True)\n",
    "\n",
    "    \n",
    "    # Accuracy\n",
    "    wins = preds_and_true.apply(lambda x: True if x[0] == True and x[1] == True else False, axis=1)\n",
    "    losses = preds_and_true.apply(lambda x: True if x[0] == False and x[1] == False else False, axis=1)\n",
    "    print('Model: ',str(model))\n",
    "    print('Total test games: ', len(y_test))\n",
    "    print('Wins predicted correctly: ',len(wins[wins == True].index))\n",
    "    print('Losses predicted correctly: ',len(losses[losses == True].index))\n",
    "    print('Percentage predicted correctly: ', (len(wins[wins == True].index) + len(losses[losses == True].index)) / len(preds_and_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4224355735219808"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SVC()\n",
      "Total test games:  159\n",
      "Wins predicted correctly:  30\n",
      "Losses predicted correctly:  54\n",
      "Percentage predicted correctly:  0.5283018867924528\n",
      "Model:  AdaBoostClassifier()\n",
      "Total test games:  159\n",
      "Wins predicted correctly:  28\n",
      "Losses predicted correctly:  49\n",
      "Percentage predicted correctly:  0.48427672955974843\n",
      "Model:  RandomForestClassifier()\n",
      "Total test games:  159\n",
      "Wins predicted correctly:  22\n",
      "Losses predicted correctly:  49\n",
      "Percentage predicted correctly:  0.44654088050314467\n",
      "Model:  GradientBoostingClassifier()\n",
      "Total test games:  159\n",
      "Wins predicted correctly:  26\n",
      "Losses predicted correctly:  51\n",
      "Percentage predicted correctly:  0.48427672955974843\n",
      "Model:  HistGradientBoostingClassifier()\n",
      "Total test games:  159\n",
      "Wins predicted correctly:  25\n",
      "Losses predicted correctly:  54\n",
      "Percentage predicted correctly:  0.4968553459119497\n",
      "[15:49:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Model:  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Total test games:  159\n",
      "Wins predicted correctly:  24\n",
      "Losses predicted correctly:  49\n",
      "Percentage predicted correctly:  0.4591194968553459\n",
      "Model:  QuadraticDiscriminantAnalysis()\n",
      "Total test games:  159\n",
      "Wins predicted correctly:  29\n",
      "Losses predicted correctly:  53\n",
      "Percentage predicted correctly:  0.5157232704402516\n",
      "Model:  KNeighborsClassifier()\n",
      "Total test games:  159\n",
      "Wins predicted correctly:  28\n",
      "Losses predicted correctly:  56\n",
      "Percentage predicted correctly:  0.5283018867924528\n"
     ]
    }
   ],
   "source": [
    "# Train and test models\n",
    "\n",
    "test_size = len(data[(data['Date'] > season_dict[year][0])]) / len(data)\n",
    "test_size = 0.08\n",
    "\n",
    "predictions_array = []\n",
    "\n",
    "models_array = [svc, ADBC, RFC, GBC, HGBC, XGB, QDA, KNC]\n",
    "\n",
    "for model in models_array:\n",
    "    train_model(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out past predictions to back test in excel\n",
    "predictions_array\n",
    "\n",
    "excel_backtest = pd.DataFrame()\n",
    "for i in predictions_array:\n",
    "    excel_backtest = pd.concat([excel_backtest, i], axis=1)\n",
    "\n",
    "excel_backtest.columns =['SVC', 'ADBC', 'RFC', 'GBC', 'HGBC', 'XGB', 'QDA', 'KNC']\n",
    "\n",
    "# Merge Excel Backtest with data dates and teams\n",
    "excel_backtest = pd.concat([data, excel_backtest], axis=1)\n",
    "excel_backtest = excel_backtest[['Date', 'Visitor', 'Home', 'Home Win', 'SVC', 'ADBC', 'RFC', 'GBC', 'HGBC', 'XGB', 'QDA', 'KNC']]\n",
    "\n",
    "excel_backtest.dropna(inplace=True)\n",
    "\n",
    "excel_backtest.to_excel('Excel Backtest.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make future predictions\n",
    "\n",
    "future_models = [svc, ADBC, RFC, GBC, HGBC, XGB, QDA, KNC]\n",
    "\n",
    "def make_preds(X_train, y_train, X_predict, model):\n",
    "    # Train\n",
    "    pipe = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), model)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_predict)\n",
    "    return preds\n",
    "\n",
    "# Append the predictions onto the entire data and keep only date, teams and prediction columns\n",
    "future_predictions_array = []\n",
    "\n",
    "for model in future_models:\n",
    "    preds = make_preds(X_train, y_train, X_predict, model)\n",
    "    future_predictions_array.append(preds)\n",
    "\n",
    "len(future_predictions_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out predictions for Feb, Mar and April to backtest, both imputed and data leakage predictions\n",
    "# If profit > with data leakage then okay\n",
    "\n",
    "# Backtest in py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: svc\n",
      "Best params are : {'svc__C': 1, 'svc__decision_function_shape': 'ovo', 'svc__kernel': 'linear', 'svc__probability': True, 'svc__shrinking': True}\n",
      "Best training accuracy: 0.659\n",
      "Test set accuracy score for best params: 0.605 \n",
      "\n",
      "Estimator: RFC\n",
      "Best params are : {'adaboostclassifier__base_estimator': None, 'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 200}\n",
      "Best training accuracy: 0.668\n",
      "Test set accuracy score for best params: 0.617 \n",
      "\n",
      "Estimator: ADBC\n",
      "Best params are : {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': 9, 'randomforestclassifier__max_leaf_nodes': 10, 'randomforestclassifier__min_samples_split': 9, 'randomforestclassifier__n_estimators': 200, 'randomforestclassifier__oob_score': True, 'randomforestclassifier__warm_start': True}\n",
      "Best training accuracy: 0.668\n",
      "Test set accuracy score for best params: 0.617 \n",
      "\n",
      "Estimator: GBC\n",
      "Best params are : {'gradientboostingclassifier__criterion': 'friedman_mse', 'gradientboostingclassifier__learning_rate': 0.01, 'gradientboostingclassifier__loss': 'deviance', 'gradientboostingclassifier__n_estimators': 200, 'gradientboostingclassifier__subsample': 1}\n",
      "Best training accuracy: 0.662\n",
      "Test set accuracy score for best params: 0.607 \n",
      "\n",
      "Estimator: HGBC\n",
      "Best params are : {'histgradientboostingclassifier__learning_rate': 0.01, 'histgradientboostingclassifier__loss': 'auto', 'histgradientboostingclassifier__max_iter': 100, 'histgradientboostingclassifier__max_leaf_nodes': 20, 'histgradientboostingclassifier__min_samples_leaf': 15}\n",
      "Best training accuracy: 0.661\n",
      "Test set accuracy score for best params: 0.603 \n",
      "\n",
      "Estimator: XGB\n",
      "[09:11:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params are : {'xgbclassifier__colsample_bytree': 0.4, 'xgbclassifier__max_depth': 15, 'xgbclassifier__n_estimators': 100, 'xgbclassifier__reg_alpha': 1.2, 'xgbclassifier__reg_lambda': 1.3, 'xgbclassifier__subsample': 0.8}\n",
      "Best training accuracy: 0.645\n",
      "Test set accuracy score for best params: 0.582 \n",
      "\n",
      "Estimator: KNC\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-400-c810b0c24177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nEstimator: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgrid_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best params are : %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;31m# Best training data accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mintegers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m         \"\"\"\n\u001b[1;32m--> 683\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 645\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n\u001b[1;32m---> 99\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m    100\u001b[0m             )\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "## HYPER PARAM TUNING\n",
    "\n",
    "models_array = [svc, ADBC, RFC, GBC, HGBC, XGB, QDA, KNC]\n",
    "\n",
    "pipe_SVC = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), svc)\n",
    "\n",
    "pipe_ADBC = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), ADBC)\n",
    "\n",
    "pipe_RFC = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), RFC)\n",
    "\n",
    "pipe_GBC = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), GBC)\n",
    "\n",
    "pipe_HGBC = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), HGBC)\n",
    "\n",
    "pipe_XGB = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), XGB)\n",
    "\n",
    "pipe_QDA = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), QDA)\n",
    "\n",
    "pipe_KNC = make_pipeline(SimpleImputer(),StandardScaler(),SelectKBest(f_regression, k='all'), KNC)\n",
    "\n",
    "param_range = [1,3,6,9,10]\n",
    "param_range_fl = [1.0, 0.5]\n",
    "\n",
    "grid_params_svc = [{'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'], \n",
    "                    'svc__C': param_range, 'svc__shrinking': [True, False],\n",
    "                  'svc__probability': [True, False], 'svc__decision_function_shape': ['ovo', 'ovr']}]\n",
    "\n",
    "grid_params_adbc = [{'adaboostclassifier__base_estimator': [None, 'svc', 'randomforestclassifier', 'knearestneighbors'],\n",
    "                    'adaboostclassifier__n_estimators': [50, 100, 200], 'adaboostclassifier__learning_rate': [0.01, 0.1, 1, 3]}]\n",
    "\n",
    "grid_params_rf = [{'randomforestclassifier__n_estimators': [50, 100, 150, 200], 'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "                'randomforestclassifier__max_depth': param_range,\n",
    "                'randomforestclassifier__min_samples_split': param_range[1:], 'randomforestclassifier__max_leaf_nodes':[5, 10, 30, None],\n",
    "                  'randomforestclassifier__oob_score': [True, False], 'randomforestclassifier__warm_start': [True, False]\n",
    "                  }]\n",
    "\n",
    "grid_params_gbc = [{'gradientboostingclassifier__loss': ['deviance', 'exponential'], 'gradientboostingclassifier__learning_rate': [0.01, 0.1, 1, 3],\n",
    "                   'gradientboostingclassifier__n_estimators': [200, 250, 300], 'gradientboostingclassifier__subsample': [1,2,3,4],\n",
    "                   'gradientboostingclassifier__criterion': ['friedman_mse', 'mse', 'mae']}]\n",
    "\n",
    "grid_params_hgbc = [{'histgradientboostingclassifier__loss': ['auto', 'binary_crossentropy', 'categorical_crossentropy'],\n",
    "                    'histgradientboostingclassifier__learning_rate': [0.01, 0.1, 1], 'histgradientboostingclassifier__max_iter': [80,100,150,200],\n",
    "                    'histgradientboostingclassifier__max_leaf_nodes': [20, 31, 40, None], 'histgradientboostingclassifier__min_samples_leaf': [2, 5, 12, 15]}]\n",
    "\n",
    "grid_params_xgb = [{'xgbclassifier__n_estimators': [100, 200, 400, 600], 'xgbclassifier__colsample_bytree':[0.4, 0.6, 0.8,1],\n",
    "                   'xgbclassifier__max_depth': [15, 20, 25], 'xgbclassifier__reg_alpha': [1.1, 1.2, 1.3],\n",
    "                   'xgbclassifier__reg_lambda':[1.1, 1.2, 1.3], 'xgbclassifier__subsample':[0.7, 0.8, 0.9]}]\n",
    "\n",
    "grid_params_knc = [{'kneighborsclassifier__n_neighbors':[2,5,8,10], 'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "                   'kneighborsclassifier__algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], 'kneighborsclassifier__leaf_size':[20,30,40],\n",
    "                   'kneighborsclassifier__p':[1,2]}]\n",
    "\n",
    "svc = GridSearchCV(estimator=pipe_SVC, param_grid=grid_params_svc,\n",
    "                  scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "RFC = GridSearchCV(estimator=pipe_RFC,\n",
    "            param_grid=grid_params_rf,\n",
    "            scoring='accuracy',\n",
    "            cv=10, \n",
    "            n_jobs=-1)\n",
    "\n",
    "ADBC = GridSearchCV(estimator=pipe_ADBC,\n",
    "                   param_grid = grid_params_adbc,\n",
    "                   scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "GBC = GridSearchCV(estimator=pipe_GBC,\n",
    "                  param_grid = grid_params_gbc,\n",
    "                  scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "HGBC = GridSearchCV(estimator=pipe_HGBC,\n",
    "                   param_grid=grid_params_hgbc,\n",
    "                   scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "XGB = GridSearchCV(estimator=pipe_XGB,\n",
    "                  param_grid = grid_params_xgb,\n",
    "                  scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "KNC = GridSearchCV(estimator=pipe_KNC,\n",
    "                  param_grid = grid_params_knc,\n",
    "                  scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "grids = [svc, ADBC, RFC, GBC, HGBC, XGB, QDA, KNC]\n",
    "\n",
    "grid_dict = { \n",
    "        0: 'svc', 1: 'ADBC', 2: 'RFC', 3: 'GBC', 4: 'HGBC', 5:'XGB', 6: 'KNC'}\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, shuffle=False)\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    gs.fit(x_train, y_train)\n",
    "    print('Best params are : %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(x_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
